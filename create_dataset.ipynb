{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lNjDUv8R6ilW"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from github import Github"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7CMxnFu6zS4",
        "outputId": "70104094-4771-4d99-bfcd-24be6f081c8e"
      },
      "outputs": [],
      "source": [
        "# Inserire il token generato su GitHub\n",
        "token = \"TOKEN\"\n",
        "\n",
        "# Definire l'URL dell'API di GitHub\n",
        "url = \"https://api.github.com/user\"\n",
        "\n",
        "# Definire l'header con l'autenticazione tramite token\n",
        "headers = {\n",
        "    \"Authorization\": f\"Token {token}\"\n",
        "}\n",
        "\n",
        "# Fare la richiesta all'API di GitHub\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "# Stampare la risposta ottenuta dall'API di GitHub\n",
        "print(response.json())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbh8GTTL7IZ3"
      },
      "outputs": [],
      "source": [
        "g = Github(token)\n",
        "repos = g.get_repos()\n",
        "users = []\n",
        "num_repos = 2000\n",
        "repos_to_shuffle = 3000\n",
        "repos = list(repos[:repos_to_shuffle])\n",
        "\n",
        "# To repeat the same random selection we can fix the seed\n",
        "np.random.seed(33)\n",
        "repos = np.random.choice(repos, num_repos, replace=False)\n",
        "\n",
        "repos_dataset = []\n",
        "# repos = [\"r_\"+str(i)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c13fKS197hIl",
        "outputId": "9fbd83e9-0532-4681-eff6-5504f0ae872d"
      },
      "outputs": [],
      "source": [
        "users = []\n",
        "languages_list = []\n",
        "for i, repo in enumerate(repos):\n",
        "    try:\n",
        "        r_id = \"r_\" + str(i)\n",
        "        full_name = repo.full_name\n",
        "        topics = repo.get_topics()\n",
        "        print(f\"Topics for {repo.name}: {topics}\")\n",
        "        n_star = repo.stargazers_count\n",
        "        print (f\"Stars for {repo.name}: {n_star}\")\n",
        "        n_fork = repo.forks_count\n",
        "        print (f\"Forks for {repo.name}: {n_fork}\")\n",
        "        languages = repo.get_languages()\n",
        "        lan = list(languages.keys())\n",
        "        total_lines = sum(languages.values())\n",
        "        language_percentages = {k: v / total_lines * 100 for k, v in languages.items()}\n",
        "        l_percentages = ['{:.2f}'.format(p) for p in language_percentages.values()]\n",
        "        print(f\"Languages for {repo.name}: {lan}\")\n",
        "        print(f\"Languages for {repo.name}: {l_percentages}\")\n",
        "        \n",
        "        repos_dataset.append({'id': r_id, 'name': full_name, 'topics': topics, 'n_star': n_star, 'n_fork': n_fork, 'languages': lan, '%_lang':l_percentages})\n",
        "\n",
        "      #save languages in a list to create the nodes\n",
        "        for l in languages:\n",
        "            if l not in languages_list:\n",
        "                languages_list.append(l)\n",
        "\n",
        "        #contributors\n",
        "        cs = repo.get_contributors()\n",
        "        commits = repo.get_commits()\n",
        "        for c in cs:\n",
        "            c_commits = 0\n",
        "            for commit in commits:\n",
        "                if commit.author.login == c.login:\n",
        "                    c_commits += 1\n",
        "            c_data = {'repos': r_id, 'user': c.login, 'commits': c_commits}\n",
        "            #print numeber of commits for each contributor\n",
        "            print(f\"Commits for {c.login}: {c_commits}\")\n",
        "            users.append(c_data)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print('Error for repo: ', repo.full_name, e)\n",
        "        continue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create users.csv\n",
        "users_df = pd.DataFrame(users)\n",
        "\n",
        "users_df = users_df.groupby('user').agg({'commits': list, 'repos': list}).reset_index()\n",
        "users_id = ['u_'+str(i) for i in range(len(users_df))]\n",
        "users_df['id'] = users_id\n",
        "users_df = users_df[['id', 'user', 'repos', 'commits']]\n",
        "\n",
        "users_df.to_csv('dataset/users.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#create file languages.csv with the id and languages\n",
        "languages_df = pd.DataFrame(languages_list)\n",
        "\n",
        "languages_id = ['l_'+str(i) for i in range(len(languages_df))]\n",
        "languages_df['id'] = languages_id\n",
        "languages_df = languages_df[['id', languages_df.columns[0]]]   \n",
        "languages_df.columns = ['id', 'language']\n",
        "\n",
        "languages_df.to_csv('dataset/languages.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGXAm9hV-5qz"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame(repos_dataset).to_csv('dataset/repos.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "repos_df = pd.DataFrame(repos_dataset)\n",
        "\n",
        "languages_df = pd.read_csv('languages.csv')\n",
        "language_id_dict = dict(zip(languages_df['language'], languages_df['id']))\n",
        "repos_df['languages'] = repos_df['languages'].apply(lambda x: [language_id_dict[l] for l in x])\n",
        "\n",
        "repos_df.to_csv('dataset/repos.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
